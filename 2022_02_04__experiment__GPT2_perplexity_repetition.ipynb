{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022_02_04__experiment__GPT2_perplexity_repetition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgNSq8XrGc6NjMCcgfr13B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee7e8f1766694edf88884aebe5739353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e5450b70e154103b58b0faa97e1004d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc33ddf34e45488ebc86054d06a0a9c2",
              "IPY_MODEL_f725879660e44a10b292e8959f0a9755",
              "IPY_MODEL_ad6a27255c614457adc55c1df7926421"
            ]
          }
        },
        "9e5450b70e154103b58b0faa97e1004d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc33ddf34e45488ebc86054d06a0a9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f36d379c0d8e41fa85dc32743efe5cf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d540fcbc584e41f0bf7d2167bdc8aa21"
          }
        },
        "f725879660e44a10b292e8959f0a9755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3bed27497eea489ebc4ba5b178ea7ccb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd294d488a844af5abef0830750a463d"
          }
        },
        "ad6a27255c614457adc55c1df7926421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ccaccfc0fbf42168c54b2fb2cdf75c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 1.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96aaa18dc12e419fbc190ae3547a8fd4"
          }
        },
        "f36d379c0d8e41fa85dc32743efe5cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d540fcbc584e41f0bf7d2167bdc8aa21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bed27497eea489ebc4ba5b178ea7ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd294d488a844af5abef0830750a463d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ccaccfc0fbf42168c54b2fb2cdf75c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96aaa18dc12e419fbc190ae3547a8fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b893bcef74534fa7a25b04274959dfda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eee2893a53dc43ca90fbb761e9d6927b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53088cbcdea044f9bead85ef6207686d",
              "IPY_MODEL_11f35aebfd884b17912bfd1dd747c942",
              "IPY_MODEL_212222db2c80443b9c52390ea2b3e501"
            ]
          }
        },
        "eee2893a53dc43ca90fbb761e9d6927b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53088cbcdea044f9bead85ef6207686d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb71d04a2ded404eaa49ec30838205e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e44c618881de4cf8bc1aa756e64080ba"
          }
        },
        "11f35aebfd884b17912bfd1dd747c942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89d58506a3674bb5a5ca3a762c50c229",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7d6f774ed25411db3b554c88ba0fcc0"
          }
        },
        "212222db2c80443b9c52390ea2b3e501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cec47b9e511e4c5bb53c0b965a7f59fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 1.43MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5772a2cad438472f929e94ff6cb1be62"
          }
        },
        "bb71d04a2ded404eaa49ec30838205e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e44c618881de4cf8bc1aa756e64080ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89d58506a3674bb5a5ca3a762c50c229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7d6f774ed25411db3b554c88ba0fcc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cec47b9e511e4c5bb53c0b965a7f59fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5772a2cad438472f929e94ff6cb1be62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbf17af76b904af98d39a71922fe1851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f67afa5b0bb74f19b14de8d18e15f342",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1161ca0ca8d64902b99ea321dfb660e3",
              "IPY_MODEL_9efada65ea2d487b8b15f32ff8a7c87a",
              "IPY_MODEL_379c2276740d4f43843c9f79627e4bcf"
            ]
          }
        },
        "f67afa5b0bb74f19b14de8d18e15f342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1161ca0ca8d64902b99ea321dfb660e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0eac47958ff44922bafaf4da06eaee9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f620583ecf4643dcbfd661944275ee61"
          }
        },
        "9efada65ea2d487b8b15f32ff8a7c87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c37bd3d400d340e8a867046356f72a32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 666,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 666,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6fd1e17214c4fc1a6ee4e6ee7a0554d"
          }
        },
        "379c2276740d4f43843c9f79627e4bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a026307ae2504085b71a0e407eec6419",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 666/666 [00:00&lt;00:00, 17.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b293616047a64dc887a609474f5544f6"
          }
        },
        "0eac47958ff44922bafaf4da06eaee9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f620583ecf4643dcbfd661944275ee61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c37bd3d400d340e8a867046356f72a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6fd1e17214c4fc1a6ee4e6ee7a0554d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a026307ae2504085b71a0e407eec6419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b293616047a64dc887a609474f5544f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d206b701afd64ffb912265eef4e9e47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c87c442c622499a990ef4ad3b473857",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a26d20e7166048e9a2480b7d8dc79eff",
              "IPY_MODEL_2b7cc80736ab4d0597b81cb33706ecba",
              "IPY_MODEL_05468d25a8be4a41bad403237ca3ab0e"
            ]
          }
        },
        "1c87c442c622499a990ef4ad3b473857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a26d20e7166048e9a2480b7d8dc79eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e49efad97f7646b6a0b90a71201b98a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef76e82eeb4949ae9862b616f71ea025"
          }
        },
        "2b7cc80736ab4d0597b81cb33706ecba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8057073a80e64bc0940f2ca0a6223184",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3096618024,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3096618024,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62601760e91d4a54919c747f3e2be734"
          }
        },
        "05468d25a8be4a41bad403237ca3ab0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d5c30f40bf34fa581e452cb30615e1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.88G/2.88G [01:47&lt;00:00, 29.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9c0c760e4d64bdf8835056801601cf5"
          }
        },
        "e49efad97f7646b6a0b90a71201b98a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef76e82eeb4949ae9862b616f71ea025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8057073a80e64bc0940f2ca0a6223184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62601760e91d4a54919c747f3e2be734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d5c30f40bf34fa581e452cb30615e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9c0c760e4d64bdf8835056801601cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d85f562ae7474f0b8d9865a9d578b160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9c6e9f012714075bfb2221e543cdfbe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_214155995b2e4f28929b63b8d50a7839",
              "IPY_MODEL_c18c9616a41241cc9859a45523717488",
              "IPY_MODEL_1e51f59ffd444c00ba85ef82f9945a01"
            ]
          }
        },
        "b9c6e9f012714075bfb2221e543cdfbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "214155995b2e4f28929b63b8d50a7839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bfe80b9c9e00419e8d93c06dfd442fa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_384dd4a329804961b7d17d6963d3cf50"
          }
        },
        "c18c9616a41241cc9859a45523717488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0ed7aa46fd841f180e9c8ed4efbcf71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3247202234,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3247202234,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d23822bbc2944b9b0165a049e18f7af"
          }
        },
        "1e51f59ffd444c00ba85ef82f9945a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73c25499af58426d8279563c1aa6365f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.02G/3.02G [01:59&lt;00:00, 33.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95e371a1acec4cbab6783239cd0a38e2"
          }
        },
        "bfe80b9c9e00419e8d93c06dfd442fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "384dd4a329804961b7d17d6963d3cf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0ed7aa46fd841f180e9c8ed4efbcf71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d23822bbc2944b9b0165a049e18f7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73c25499af58426d8279563c1aa6365f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95e371a1acec4cbab6783239cd0a38e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataJenius/GPT2_perplexity_repetition/blob/main/2022_02_04__experiment__GPT2_perplexity_repetition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lPKvZ2GY6Tw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3b1db4-044c-4b34-e18c-767bf792252a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.23.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.43.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tensorboard\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.1.0 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 2.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorboard-2.8.0\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# install requirements - 🤗 Transformers\n",
        "#----------------------------------------\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q tensorflow==2.1\n",
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# load all dependencies\n",
        "#------------------------\n",
        "import tensorflow as tf\n",
        "from transformers import GPT2LMHeadModel, TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import string\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "03gHbMtB7dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c8c406a9-f6bc-4579-dd18-1cb7af6bdc00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7a309bc0abaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFGPT2LMHeadModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------\n",
        "# load models and tokenizer from 🤗\n",
        "#-------------------------------------\n",
        "# using GPT2-large\n",
        "device = \"cuda\"\n",
        "model_id = \"gpt2-large\"\n",
        "\n",
        "# load our tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_id)\n",
        "\n",
        "# using two models because I can't find a perplexity calculation with TFGPT2LMHeadModel\n",
        "# load models with the EOS token as PAD token to avoid warnings\n",
        "gmodel = TFGPT2LMHeadModel.from_pretrained(model_id, pad_token_id=tokenizer.eos_token_id)\n",
        "emodel = GPT2LMHeadModel.from_pretrained(model_id, pad_token_id=tokenizer.eos_token_id).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "ee7e8f1766694edf88884aebe5739353",
            "9e5450b70e154103b58b0faa97e1004d",
            "bc33ddf34e45488ebc86054d06a0a9c2",
            "f725879660e44a10b292e8959f0a9755",
            "ad6a27255c614457adc55c1df7926421",
            "f36d379c0d8e41fa85dc32743efe5cf8",
            "d540fcbc584e41f0bf7d2167bdc8aa21",
            "3bed27497eea489ebc4ba5b178ea7ccb",
            "fd294d488a844af5abef0830750a463d",
            "1ccaccfc0fbf42168c54b2fb2cdf75c5",
            "96aaa18dc12e419fbc190ae3547a8fd4",
            "b893bcef74534fa7a25b04274959dfda",
            "eee2893a53dc43ca90fbb761e9d6927b",
            "53088cbcdea044f9bead85ef6207686d",
            "11f35aebfd884b17912bfd1dd747c942",
            "212222db2c80443b9c52390ea2b3e501",
            "bb71d04a2ded404eaa49ec30838205e3",
            "e44c618881de4cf8bc1aa756e64080ba",
            "89d58506a3674bb5a5ca3a762c50c229",
            "d7d6f774ed25411db3b554c88ba0fcc0",
            "cec47b9e511e4c5bb53c0b965a7f59fd",
            "5772a2cad438472f929e94ff6cb1be62",
            "cbf17af76b904af98d39a71922fe1851",
            "f67afa5b0bb74f19b14de8d18e15f342",
            "1161ca0ca8d64902b99ea321dfb660e3",
            "9efada65ea2d487b8b15f32ff8a7c87a",
            "379c2276740d4f43843c9f79627e4bcf",
            "0eac47958ff44922bafaf4da06eaee9e",
            "f620583ecf4643dcbfd661944275ee61",
            "c37bd3d400d340e8a867046356f72a32",
            "d6fd1e17214c4fc1a6ee4e6ee7a0554d",
            "a026307ae2504085b71a0e407eec6419",
            "b293616047a64dc887a609474f5544f6",
            "d206b701afd64ffb912265eef4e9e47b",
            "1c87c442c622499a990ef4ad3b473857",
            "a26d20e7166048e9a2480b7d8dc79eff",
            "2b7cc80736ab4d0597b81cb33706ecba",
            "05468d25a8be4a41bad403237ca3ab0e",
            "e49efad97f7646b6a0b90a71201b98a7",
            "ef76e82eeb4949ae9862b616f71ea025",
            "8057073a80e64bc0940f2ca0a6223184",
            "62601760e91d4a54919c747f3e2be734",
            "5d5c30f40bf34fa581e452cb30615e1a",
            "a9c0c760e4d64bdf8835056801601cf5",
            "d85f562ae7474f0b8d9865a9d578b160",
            "b9c6e9f012714075bfb2221e543cdfbe",
            "214155995b2e4f28929b63b8d50a7839",
            "c18c9616a41241cc9859a45523717488",
            "1e51f59ffd444c00ba85ef82f9945a01",
            "bfe80b9c9e00419e8d93c06dfd442fa3",
            "384dd4a329804961b7d17d6963d3cf50",
            "e0ed7aa46fd841f180e9c8ed4efbcf71",
            "0d23822bbc2944b9b0165a049e18f7af",
            "73c25499af58426d8279563c1aa6365f",
            "95e371a1acec4cbab6783239cd0a38e2"
          ]
        },
        "id": "3bCMHu339qR4",
        "outputId": "9d4c84a8-85dc-4f09-e9dd-ab94cb004f46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee7e8f1766694edf88884aebe5739353",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b893bcef74534fa7a25b04274959dfda",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbf17af76b904af98d39a71922fe1851",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d206b701afd64ffb912265eef4e9e47b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.88G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d85f562ae7474f0b8d9865a9d578b160",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.02G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------------\n",
        "# Load human text & prompts from Github\n",
        "#----------------------------------------\n",
        "# load into Pandas df\n",
        "human_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_human_text_and_prompts.csv\")\n",
        "\n",
        "# sanity check it loaded correctly...\n",
        "#print(human_text.iloc[0,0]) # Source\n",
        "#print(human_text.iloc[0,4]) # Prompt"
      ],
      "metadata": {
        "id": "-3HW2xKwM_3l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------\n",
        "# Beam Search\n",
        "#------------------\n",
        "# deterministic; no need to set random seed\n",
        "\n",
        "# hold output in a dataframe (easily saved/shared as csv)\n",
        "output_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our prompts based on human text\n",
        "for i, row in human_text.iterrows():\n",
        "  print(human_text.iloc[i,0])\n",
        "  print(human_text.iloc[i,4])  \n",
        "\n",
        "  # tokenize our text promp\n",
        "  input_ids = tokenizer.encode(human_text.iloc[i,4], return_tensors='tf')\n",
        "\n",
        "  # set model parameters\n",
        "  # generate 10 outputs of max length 250\n",
        "  beam_outputs = gmodel.generate(\n",
        "      input_ids, \n",
        "      num_return_sequences=10,    \n",
        "      max_length=250, \n",
        "      num_beams=15, \n",
        "      early_stopping=True)\n",
        "\n",
        "  # hold output in a dataframe (easily saved/shared as csv)\n",
        "  for j, beam_output in enumerate(beam_outputs):\n",
        "    output_text = \"{}\".format(tokenizer.decode(beam_output, skip_special_tokens=True))  \n",
        "    output_df = output_df.append(pd.DataFrame({'method':['Beam Search'],\n",
        "                                              'source':[human_text.iloc[i,0]],\n",
        "                                              'prompt':[human_text.iloc[i,4]],\n",
        "                                              'trial':[j+1],\n",
        "                                              'generated_text':[output_text]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "output_df.to_csv('data_generated_text_beam_search.csv') \n",
        "files.download('data_generated_text_beam_search.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "f9LU-K5VUdCP",
        "outputId": "f1b14c51-e62c-436d-e237-3d4e46545d41"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tale of Two Cities\n",
            "It was the best of times, it was the worst of times, it was \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-152345a19110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       early_stopping=True)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# hold output in a dataframe (easily saved/shared as csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mforced_eos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced_eos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m             )\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36m_generate_beam_search\u001b[0;34m(self, input_ids, cur_len, max_length, min_length, do_sample, early_stopping, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, num_return_sequences, length_penalty, num_beams, vocab_size, encoder_outputs, attention_mask, use_cache, forced_bos_token_id, forced_eos_token_id, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_attentions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             )\n\u001b[1;32m   1143\u001b[0m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (batch_size * num_beams, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, labels, training, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    946\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mode)\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"mode {mode} is not valid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36m_linear\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0mfirst_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"wte\" (type TFSharedEmbeddings).\n\nOOM when allocating tensor with shape[50257,1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(15, 17, 1280), dtype=float32)\n  • mode='linear'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------\n",
        "# Sampling\n",
        "#------------------\n",
        "# set seed to reproduce results\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# hold output in a dataframe (easily saved/shared as csv)\n",
        "output_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our prompts based on human text\n",
        "for i, row in human_text.iterrows():\n",
        "  print(human_text.iloc[i,0])\n",
        "  print(human_text.iloc[i,4])  \n",
        "\n",
        "  # tokenize our text promp\n",
        "  input_ids = tokenizer.encode(human_text.iloc[i,4], return_tensors='tf')\n",
        "\n",
        "  # set model parameters\n",
        "  # generate 10 outputs of max length 250\n",
        "  sampling_outputs = gmodel.generate(    \n",
        "      input_ids, \n",
        "      num_return_sequences=10,    \n",
        "      max_length=250, \n",
        "      do_sample=True,\n",
        "      top_k=0)\n",
        "\n",
        "  # hold output in a dataframe (easily saved/shared as csv)\n",
        "  for j, sampling_output in enumerate(sampling_outputs):\n",
        "    output_text = \"{}\".format(tokenizer.decode(sampling_output, skip_special_tokens=True))  \n",
        "    output_df = output_df.append(pd.DataFrame({'method':['Sampling'],\n",
        "                                              'source':[human_text.iloc[i,0]],\n",
        "                                              'prompt':[human_text.iloc[i,4]],\n",
        "                                              'trial':[j+1],\n",
        "                                              'generated_text':[output_text]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "output_df.to_csv('data_generated_text_sampling.csv') \n",
        "files.download('data_generated_text_sampling.csv')"
      ],
      "metadata": {
        "id": "ixPUEsJMyzs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------\n",
        "# Temperature (0.7)\n",
        "#--------------------\n",
        "# set seed to reproduce results\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# hold output in a dataframe (easily saved/shared as csv)\n",
        "output_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our prompts based on human text\n",
        "for i, row in human_text.iterrows():\n",
        "  print(human_text.iloc[i,0])\n",
        "  print(human_text.iloc[i,4])  \n",
        "\n",
        "  # tokenize our text promp\n",
        "  input_ids = tokenizer.encode(human_text.iloc[i,4], return_tensors='tf')\n",
        "\n",
        "  # set model parameters\n",
        "  # generate 10 outputs of max length 250\n",
        "  temperature_outputs = gmodel.generate(    \n",
        "      input_ids, \n",
        "      num_return_sequences=10,    \n",
        "      max_length=250, \n",
        "      do_sample=True,\n",
        "      top_k=0,\n",
        "      temperature=0.7)\n",
        "\n",
        "  # hold output in a dataframe (easily saved/shared as csv)\n",
        "  for j, temperature_output in enumerate(temperature_outputs):\n",
        "    output_text = \"{}\".format(tokenizer.decode(temperature_output, skip_special_tokens=True))  \n",
        "    output_df = output_df.append(pd.DataFrame({'method':['Temperature'],\n",
        "                                              'source':[human_text.iloc[i,0]],\n",
        "                                              'prompt':[human_text.iloc[i,4]],\n",
        "                                              'trial':[j+1],\n",
        "                                              'generated_text':[output_text]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "output_df.to_csv('data_generated_text_temperature.csv') \n",
        "files.download('data_generated_text_temperature.csv')"
      ],
      "metadata": {
        "id": "8pU27Bg60nxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------\n",
        "# Top-K (k=10)\n",
        "#--------------------\n",
        "# set seed to reproduce results\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# hold output in a dataframe (easily saved/shared as csv)\n",
        "output_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our prompts based on human text\n",
        "for i, row in human_text.iterrows():\n",
        "  print(human_text.iloc[i,0])\n",
        "  print(human_text.iloc[i,4])  \n",
        "\n",
        "  # tokenize our text promp\n",
        "  input_ids = tokenizer.encode(human_text.iloc[i,4], return_tensors='tf')\n",
        "\n",
        "  # set model parameters\n",
        "  # generate 10 outputs of max length 250\n",
        "  top_k_outputs = gmodel.generate(    \n",
        "      input_ids, \n",
        "      num_return_sequences=10,    \n",
        "      max_length=250, \n",
        "      do_sample=True,\n",
        "      top_k=10)\n",
        "\n",
        "  # hold output in a dataframe (easily saved/shared as csv)\n",
        "  for j, top_k_output in enumerate(top_k_outputs):\n",
        "    output_text = \"{}\".format(tokenizer.decode(top_k_output, skip_special_tokens=True))  \n",
        "    output_df = output_df.append(pd.DataFrame({'method':['Top-K'],\n",
        "                                              'source':[human_text.iloc[i,0]],\n",
        "                                              'prompt':[human_text.iloc[i,4]],\n",
        "                                              'trial':[j+1],\n",
        "                                              'generated_text':[output_text]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "output_df.to_csv('data_generated_text_top_k.csv') \n",
        "files.download('data_generated_text_top_k.csv')"
      ],
      "metadata": {
        "id": "NwjAQa-x1MRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------\n",
        "# Top-P (p=0.95)\n",
        "#--------------------\n",
        "# set seed to reproduce results\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# hold output in a dataframe (easily saved/shared as csv)\n",
        "output_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our prompts based on human text\n",
        "for i, row in human_text.iterrows():\n",
        "  print(human_text.iloc[i,0])\n",
        "  print(human_text.iloc[i,4])  \n",
        "\n",
        "  # tokenize our text promp\n",
        "  input_ids = tokenizer.encode(human_text.iloc[i,4], return_tensors='tf')\n",
        "\n",
        "  # set model parameters\n",
        "  # generate 10 outputs of max length 250\n",
        "  top_p_outputs = gmodel.generate(    \n",
        "      input_ids, \n",
        "      num_return_sequences=10,    \n",
        "      max_length=250, \n",
        "      do_sample=True,\n",
        "      top_p=0.95, \n",
        "      top_k=0)\n",
        "\n",
        "  # hold output in a dataframe (easily saved/shared as csv)\n",
        "  for j, top_p_output in enumerate(top_p_outputs):\n",
        "    output_text = \"{}\".format(tokenizer.decode(top_p_output, skip_special_tokens=True))  \n",
        "    output_df = output_df.append(pd.DataFrame({'method':['Top-P'],\n",
        "                                              'source':[human_text.iloc[i,0]],\n",
        "                                              'prompt':[human_text.iloc[i,4]],\n",
        "                                              'trial':[j+1],\n",
        "                                              'generated_text':[output_text]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "output_df.to_csv('data_generated_text_top_p.csv') \n",
        "files.download('data_generated_text_top_p.csv')"
      ],
      "metadata": {
        "id": "Zoysy6ko1tXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------\n",
        "# Load generated text from Github\n",
        "#----------------------------------\n",
        "# load into Pandas dfs\n",
        "beam_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_generated_text_beam_search.csv\")\n",
        "sampling_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_generated_text_sampling.csv\")\n",
        "temperature_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_generated_text_temperature.csv\")\n",
        "top_k_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_generated_text_top_k.csv\")\n",
        "top_p_text = pd.read_csv(\"https://raw.githubusercontent.com/DataJenius/GPT2_perplexity_repetition/main/data_generated_text_top_p.csv\")\n",
        "\n",
        "# sanity check it loaded correctly...\n",
        "print(beam_text.iloc[0,1]) # Method\n",
        "print(sampling_text.iloc[0,1]) # Method\n",
        "print(temperature_text.iloc[0,1]) # Method\n",
        "print(top_k_text.iloc[0,1]) # Method\n",
        "print(top_p_text.iloc[0,1]) # Method\n",
        "\n",
        "# combine into a single dataframe\n",
        "generated_text_df = beam_text.append(sampling_text).append(temperature_text).append(top_k_text).append(top_p_text)"
      ],
      "metadata": {
        "id": "eDv9M8SzFDtc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------\n",
        "# Function to calculate Repetitions\n",
        "# and other basic stats\n",
        "#---------------------------------------\n",
        "def calculate_repetitions(my_text, debug=False):\n",
        "  # ignore capitalization and punctuation\n",
        "  clean_text = my_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "  character_count = len(my_text)\n",
        "\n",
        "  # word-based tokens (use spaces)\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  tokens = tokenizer.tokenize(clean_text)\n",
        "  word_count = len(tokens)\n",
        "\n",
        "  # every time a 3gram is repeated +1 to total_repetitions  \n",
        "  finder = TrigramCollocationFinder.from_words(tokens)\n",
        "  total_repetitions = 0\n",
        "  for item in finder.ngram_fd.items():\n",
        "    if item[1] > 1:  # only care about repetition       \n",
        "      repetitions = item[1]-1 # the first use of a trigram is not a repetition\n",
        "      total_repetitions += repetitions   \n",
        "\n",
        "      # just for debugging\n",
        "      if debug:\n",
        "        print(item[0])\n",
        "        print('repeated '+str(repetitions)+' time(s)...')   \n",
        "        print('found '+str(total_repetitions)+' total repetition(s)...')\n",
        "  return(total_repetitions, word_count, character_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thm5U_TBIAJU",
        "outputId": "e37e139c-c5b2-411a-c924-c35e38dc9334"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "191\n",
            "1036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------\n",
        "# Function to calculate Perplexity\n",
        "#-----------------------------------\n",
        "# Stolen from: https://huggingface.co/docs/transformers/perplexity\n",
        "# when (stride > # of tokens in my_text) or (stride > # of tokens the model can process) we evaluate the model’s perplexity by autoregressively factorizing a sequence and conditioning on the ENTIRE preceding subsequence at each step\n",
        "# otherwise evaluated with a sliding-window strategy\n",
        "def calculate_perplexity(my_text, emodel, device, stride=512):\n",
        " \n",
        "  # encode our text\n",
        "  my_encodings = tokenizer(my_text, return_tensors=\"pt\")\n",
        "\n",
        "  # not sure if this stride makes any good sense given an output of 250 items\n",
        "  max_length = emodel.config.n_positions\n",
        "\n",
        "  nlls = []\n",
        "  for i in tqdm(range(0, my_encodings.input_ids.size(1), stride)):\n",
        "      begin_loc = max(i + stride - max_length, 0)\n",
        "      end_loc = min(i + stride, my_encodings.input_ids.size(1))\n",
        "      trg_len = end_loc - i  # may be different from stride on last loop\n",
        "      input_ids = my_encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "      #input_ids = output_encodings.input_ids[:, begin_loc:end_loc]\n",
        "      target_ids = input_ids.clone()\n",
        "      target_ids[:, :-trg_len] = -100\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = emodel(input_ids, labels=target_ids)\n",
        "          neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "      nlls.append(neg_log_likelihood)\n",
        "\n",
        "  ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
        "  return(ppl.item())"
      ],
      "metadata": {
        "id": "QqtIwjJ4Lwmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------\n",
        "# Evaluate all generated text\n",
        "#------------------------------\n",
        "# hold evaulations in a dataframe (easily saved/shared as csv)\n",
        "evaluate_df = pd.DataFrame()\n",
        "\n",
        "# iterate through all of our generated text\n",
        "for i, row in generated_text_df.iterrows():\n",
        "  print(generated_text_df.iloc[i,1],generated_text_df.iloc[i,2],generated_text_df.iloc[i,4])\n",
        "  total_repetitions, word_count, character_count = calculate_repetitions(generated_text_df.iloc[i,5])\n",
        "  ppl = calculate_perplexity(generated_text_df.iloc[i,5], emodel, device, 1024)\n",
        "  evaluate_df = evaluate_df.append(pd.DataFrame({'method':[generated_text_df.iloc[i,1]],\n",
        "                                                 'prompt_source':[generated_text_df.iloc[i,2]],\n",
        "                                                 'trial':[generated_text_df.iloc[i,4]],\n",
        "                                                 'word_count':[word_count], \n",
        "                                                 'character_count':[character_count], \n",
        "                                                 'total_repetitions':[total_repetitions], \n",
        "                                                 'perplexity':[ppl],                                            \n",
        "                                                 'prompt':[generated_text_df.iloc[i,3]],\n",
        "                                                 'generated_text':[generated_text_df.iloc[i,5]]}))\n",
        "\n",
        "# save our results to local CSV after iterating through all prompts\n",
        "evaluate_df.to_csv('data_evaluation_results.csv') \n",
        "files.download('data_evaluation_results.csv')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hzavArBxGlqL",
        "outputId": "32ebb8a4-91b9-4435-9bd2-394bd2350f2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam Search Tale of Two Cities 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_06547e5c-5e45-46fb-bf43-57703f0752cf\", \"data_evaluation_results.csv\", 1229)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_repetitions, word_count, character_count = calculate_repetitions(\"\"\"It was the best of times, worst of times, it was  HUMAN EVENTFULLY WRONG about half the people.. I could deal with whatever that became, and I want to hear about your lovely post about how This was on SRW... Just like once again, those people that I know say a card cannot be a dupe because they thought about drawing a bad-level card and had the card of an AUTO deck to use.\n",
        "You'd better think before spam your good, rare warzones, and to review your haxus ults (something their logs don't easily disclose, since their logs are deleted when they lose the battle)because what people keep saying is not possible because they could be receiving a card they really want from SRW...\n",
        "Annoyed by \"admins\" how do!!!! you think I got fired \"for trying to help players out!\" and more annoying, I have been afraid to post or even reply to a modmail or any message sent from SRW because the only admins I've been dealing with today had been bigots and could easily handle banning me, and they even had their friends to help them out.\n",
        "\"SNAPPY -WHAT\"\"\", True)\n",
        "print(total_repetitions)\n",
        "print(word_count)\n",
        "print(character_count)"
      ],
      "metadata": {
        "id": "rbQ7koAgGQw-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# old crap\n",
        "#------------------\n",
        "# Greedy method\n",
        "#------------------\n",
        "\n",
        "# tokenize our text promp\n",
        "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n",
        "\n",
        "# generate text \n",
        "gmodel_output = gmodel.generate(input_ids, \n",
        "                                num_return_sequences=10, \n",
        "                                max_length=250)\n",
        "\n",
        "# decode the output back into text\n",
        "output_text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
        "\n",
        "# show generated text\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "N4WQXwyY_mvE",
        "outputId": "b76a0c9e-990a-47cb-9ef2-291737cdd0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f0c73957ff00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m gmodel_output = gmodel.generate(input_ids, \n\u001b[1;32m     11\u001b[0m                                 \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                 max_length=250)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m                 assert (\n\u001b[1;32m    650\u001b[0m                     \u001b[0mnum_return_sequences\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                 ), \"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------\n",
        "# Calculate Perplexity\n",
        "#-----------------------\n",
        "def calculate_perplexity(my_text, emodel, device, stride=512):\n",
        "  # https://huggingface.co/docs/transformers/perplexity\n",
        "  # when (stride > # of tokens in my_text) or (stride > # of tokens the model can process) we evaluate the model’s perplexity by autoregressively factorizing a sequence and conditioning on the ENTIRE preceding subsequence at each step\n",
        "  # otherwise evaluated with a sliding-window strategy\n",
        "\n",
        "  # encode our text\n",
        "  my_encodings = tokenizer(my_text, return_tensors=\"pt\")\n",
        "\n",
        "  # not sure if this stride makes any good sense given an output of 250 items\n",
        "  max_length = emodel.config.n_positions\n",
        "\n",
        "  nlls = []\n",
        "  for i in tqdm(range(0, my_encodings.input_ids.size(1), stride)):\n",
        "      begin_loc = max(i + stride - max_length, 0)\n",
        "      end_loc = min(i + stride, my_encodings.input_ids.size(1))\n",
        "      trg_len = end_loc - i  # may be different from stride on last loop\n",
        "      input_ids = my_encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "      #input_ids = output_encodings.input_ids[:, begin_loc:end_loc]\n",
        "      target_ids = input_ids.clone()\n",
        "      target_ids[:, :-trg_len] = -100\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = emodel(input_ids, labels=target_ids)\n",
        "          neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "      nlls.append(neg_log_likelihood)\n",
        "\n",
        "  ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
        "  return(ppl.item())"
      ],
      "metadata": {
        "id": "RdaBvwubBUfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run ppl function\n",
        "ppl = calculate_perplexity(output_text, emodel, device, 1024)\n",
        "ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYwreBYBf3P4",
        "outputId": "945707cd-a106-4b2e-b5e1-7f4aff1c4701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 47.61it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3632889986038208"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------\n",
        "# Calculate Repetitions\n",
        "#------------------------\n",
        "def calculate_repetitions(my_text, debug=False):\n",
        "  # ignore capitalization and punctuation\n",
        "  clean_text = my_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  # word-based tokens (use spaces)\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  tokens = tokenizer.tokenize(clean_text)\n",
        "\n",
        "  # every time a 3gram is repeated +1 to total_repetitions  \n",
        "  finder = TrigramCollocationFinder.from_words(tokens)\n",
        "  total_repetitions = 0\n",
        "  for item in finder.ngram_fd.items():\n",
        "    if item[1] > 1:  # only care about repetition       \n",
        "      repetitions = item[1]-1 # the first use of a trigram is not a repetition\n",
        "      total_repetitions += repetitions   \n",
        "\n",
        "      # just for debugging\n",
        "      if debug:\n",
        "        print(item[0])\n",
        "        print('repeated '+str(repetitions)+' time(s)...')   \n",
        "        print('found '+str(total_repetitions)+' total repetition(s)...')\n",
        "  return(total_repetitions)"
      ],
      "metadata": {
        "id": "efxwTENkfzrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run ppl function\n",
        "rpt = calculate_repetitions(\"\\\"Forty-two!\\\" yelled Loonquawl. \\\"Is that all you’ve got to show for seven and a half million years’ work?\\\"\\n\\n\\\"I checked it very thoroughly,\\\" said the computer, \\\"and that quite definitely is the answer. I think the problem, to be quite honest with you, is that you've never actually known what the question is.\\\"\\n\\n\\\"But it was the Great Question! The Ultimate Question of Life, the Universe and Everything!\\\" howled Loonquawl.\\n\\n\\\"Yes,\\\" said Deep Thought with the air of one who suffers fools gladly, \\\"but what actually is it?\\\"\\n\\nA slow stupefied silence crept over the men as they stared at the computer and then at each other. \\n\\n\\\"Well, you know, it’s just Everything… Everything…\\\" offered Phouchg weakly.\\n\\n\\\"Exactly!\\\" said Deep Thought. \\\"So once you do know what the question actually is, you’ll know what the answer means.\\\"\", True)\n",
        "#rpt = calculate_repetitions(\"Yes we can change! Yes we can stop!\", True)\n",
        "#rpt = calculate_repetitions(output_text, True)\n",
        "rpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlAvoYqFdoJu",
        "outputId": "bbc90676-cde6-4d6a-c9d9-3781957b6699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('the', 'computer', 'and')\n",
            "repeated 1 time(s)...\n",
            "found 1 total repetition(s)...\n",
            "('what', 'the', 'question')\n",
            "repeated 1 time(s)...\n",
            "found 2 total repetition(s)...\n",
            "('said', 'deep', 'thought')\n",
            "repeated 1 time(s)...\n",
            "found 3 total repetition(s)...\n",
            "('know', 'what', 'the')\n",
            "repeated 1 time(s)...\n",
            "found 4 total repetition(s)...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#output_text\n",
        "\n",
        "output_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "#output_text.lower().replace(string.punctuation,'')\n",
        "#string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "WvaMprSqhqg5",
        "outputId": "d31700aa-6c05-46cb-a043-48f8559c435f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i enjoy walking with my cute dog but im not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not sure if ill ever be able to walk with my dog im not sure if ill ever be able to walk with my dog\\n\\nim not'"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show generated text\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW4H3smMlPX2",
        "outputId": "60793a08-f229-4aac-a673-8d095e6c0d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not\n"
          ]
        }
      ]
    }
  ]
}